{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AML - VOC 2012 - test set evaluation"
      ],
      "metadata": {
        "id": "FUyoVEVXrmwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "PeSw2T35rspZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "dTODzbFRr0cF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input"
      ],
      "metadata": {
        "id": "bUAx4o_bHHCM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility"
      ],
      "metadata": {
        "id": "DYuyCShNn122"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.keras.utils.register_keras_serializable()\n",
        "def perfect_accuracy(y_true, y_pred, threshold=0.5):\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "\n",
        "    y_pred_bin = tf.cast(y_pred >= threshold, tf.int32)\n",
        "\n",
        "    correct_predictions = tf.reduce_all(tf.equal(y_true, y_pred_bin), axis=1)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(correct_predictions, tf.float32))"
      ],
      "metadata": {
        "id": "loFe8hv7R25k"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASELINE_IMG_SIZE = (128, 128)\n",
        "RESNET50_IMG_SIZE = (224, 224)"
      ],
      "metadata": {
        "id": "b9xZdGMusFEI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/'\n",
        "BASE_DIR = ROOT_DIR + 'AML/project/test/'\n",
        "#BASE_DIR = ROOT_DIR + 'project/test/'\n",
        "PARTITION_FILENAMES = [f\"voc_test_partition_{i}.npz\" for i in range(3)]\n",
        "PARTITION_PATHS = [os.path.join(BASE_DIR, filename) for filename in PARTITION_FILENAMES]\n",
        "\n",
        "PARTITION_PATHS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOz2ZLh3sKYM",
        "outputId": "3dadc850-46ae-404c-ed85-0e24c0ba8a70"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/AML/project/test/voc_test_partition_0.npz',\n",
              " '/content/drive/MyDrive/AML/project/test/voc_test_partition_1.npz',\n",
              " '/content/drive/MyDrive/AML/project/test/voc_test_partition_2.npz']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(images: np.ndarray, resize, preprocess_fn):\n",
        "    resized_images = []\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "        resized_image = tf.image.resize(images[i], resize).numpy()\n",
        "        if preprocess_fn is not None:\n",
        "            resized_image = preprocess_fn(resized_image)\n",
        "        resized_images.append(resized_image)\n",
        "\n",
        "    resized_images = np.array(resized_images)\n",
        "    del images\n",
        "\n",
        "    return resized_images"
      ],
      "metadata": {
        "id": "BAEOnlZGtUPd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_preprocess_images(images: np.ndarray):\n",
        "    return preprocess_images(images, BASELINE_IMG_SIZE, lambda x: x / 255.0)"
      ],
      "metadata": {
        "id": "zebzB8E_I13j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_preprocess_images(images: np.ndarray):\n",
        "    return preprocess_images(images, RESNET50_IMG_SIZE, resnet_preprocess_input)"
      ],
      "metadata": {
        "id": "yKDdCTAnIqV1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYMn6FlSsNAZ",
        "outputId": "30d3dd95-c2ee-4029-ca11-2b13249af46a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = [\n",
        "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
        "    \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
        "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
        "]\n",
        "PRED_FOLDER = \"./results/VOC2012/Main\"\n",
        "FILE_FORMAT_PRED = \"comp2_cls_test_{}.txt\"\n",
        "FILE_FORMAT_DET = \"comp4_det_test_{}.txt\""
      ],
      "metadata": {
        "id": "rN4V6_v6OwVd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "0Vgao-jOn5UF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def serialize_predictions(\n",
        "    model_filepath,\n",
        "    partition_paths,\n",
        "    preprocess_fn,\n",
        "    batch_size=1024,\n",
        "    classes=CLASSES,\n",
        "    pred_folder=PRED_FOLDER,\n",
        "    file_format_pred=FILE_FORMAT_PRED,\n",
        "    file_format_det=FILE_FORMAT_DET):\n",
        "  preds = []\n",
        "  filenames = []\n",
        "\n",
        "  print(f\"Loading model from '{model_filepath}'\")\n",
        "  model = tf.keras.models.load_model(model_filepath)\n",
        "\n",
        "  for i, partition in enumerate(partition_paths):\n",
        "    print(f\"Partition {i + 1}/{len(partition_paths)}:\")\n",
        "    print(f\"\\tLoading partition...\")\n",
        "    partition_data = np.load(partition, allow_pickle=True)\n",
        "    partition_images = partition_data['images']\n",
        "    partition_filenames = partition_data['filenames']\n",
        "\n",
        "    print(f\"\\tPreprocessing partition...\")\n",
        "    partition_images = preprocess_fn(partition_images)\n",
        "\n",
        "    print(f\"\\tComputing predictions...\")\n",
        "    i = 0\n",
        "    partition_preds_list = []\n",
        "    while i < len(partition_images):\n",
        "      print(f\"\\t\\tBatch {(i // batch_size) + 1}/{math.ceil(len(partition_images) / batch_size)}\")\n",
        "      partition_preds_list = partition_preds_list + model.predict(partition_images[i:i+batch_size]).tolist()\n",
        "      i += batch_size\n",
        "\n",
        "    if i < len(partition_images):\n",
        "      print(f\"\\t\\tBatch {(i / batch_size) + 1}/{math.ceil(len(partition_images) // batch_size)}\")\n",
        "      partition_preds_list = partition_preds_list + model.predict(partition_images[i:]).tolist()\n",
        "\n",
        "    partition_preds = np.array(partition_preds_list)\n",
        "    assert partition_preds.shape == (len(partition_images), len(classes))\n",
        "    del partition_data\n",
        "    del partition_images\n",
        "    del partition_preds_list\n",
        "\n",
        "    preds.append(partition_preds)\n",
        "    filenames.append(partition_filenames)\n",
        "\n",
        "  print(f\"Concatenating partitions predictions...\")\n",
        "  preds = np.concatenate(preds)\n",
        "  filenames = np.concatenate(filenames)\n",
        "\n",
        "  print(f\"Sorting predictions by filename...\")\n",
        "  indices = np.argsort(filenames)\n",
        "  preds = preds[indices]\n",
        "  filenames = filenames[indices]\n",
        "\n",
        "  print(\"Serializing predictions...\")\n",
        "  os.makedirs(pred_folder, exist_ok=True)\n",
        "  preds_t = preds.T\n",
        "  for i, c in enumerate(classes):\n",
        "    file_path = os.path.join(pred_folder, file_format_pred.format(c))\n",
        "    print(f\"\\tSerializing predictions for class '{c}' to '{file_path}'\")\n",
        "    f = open(file_path, 'w')\n",
        "    for filename, pred in zip(filenames, preds_t[i]):\n",
        "      f.write(f\"{filename} {pred:.6f}\\n\")\n",
        "    f.close()\n",
        "\n",
        "  del preds\n",
        "\n",
        "  print(\"Mocking results for detection task...\")\n",
        "  for i, c in enumerate(classes):\n",
        "    file_path = os.path.join(pred_folder, file_format_det.format(c))\n",
        "    print(f\"\\tMocking detections for class '{c}' to '{file_path}'\")\n",
        "    f = open(file_path, 'w')\n",
        "    for filename in filenames:\n",
        "      f.write(f\"{filename} 0.013737 1.000000 147.000000 114.000000 242.000000\\n\")\n",
        "    f.close()\n",
        "\n",
        "  del filenames"
      ],
      "metadata": {
        "id": "YgG2Sbmm-PCX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_path = \"/content/drive/MyDrive/AML/project/models/model_base_resnet.keras\"\n",
        "resnet_filename, _ = os.path.splitext(os.path.basename(resnet_path))\n",
        "\n",
        "resnet_path, resnet_filename"
      ],
      "metadata": {
        "id": "zXnrKuTYPUzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b933a9-cc51-49ce-bb86-f7a05597b7d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/AML/project/models/model_base_resnet.keras',\n",
              " 'model_base_resnet')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_path = \"/content/drive/MyDrive/AML/project/models/baseline_augmented_model.keras\"\n",
        "baseline_filename, _ = os.path.splitext(os.path.basename(baseline_path))\n",
        "\n",
        "baseline_path, baseline_filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU4-cxrkc1DH",
        "outputId": "34a01f20-407a-4de8-c6b4-76f97e36a5ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/AML/project/models/baseline_augmented_model.keras',\n",
              " 'baseline_augmented_model')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = resnet_path\n",
        "model_filename = resnet_filename\n",
        "\n",
        "serialize_predictions(\n",
        "    baseline_path,\n",
        "    PARTITION_PATHS,\n",
        "    baseline_preprocess_images,\n",
        "    batch_size = 2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bea9970-a9fd-4e74-8569-6539e1ea04b5",
        "id": "2GsM7JR_EkXP"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from '/content/drive/MyDrive/AML/project/models/baseline_augmented_model.keras'\n",
            "Partition 1/3:\n",
            "\tLoading partition...\n",
            "\tPreprocessing partition...\n",
            "\tComputing predictions...\n",
            "\t\tBatch 1/3\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
            "\t\tBatch 2/3\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\t\tBatch 3/3\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Partition 2/3:\n",
            "\tLoading partition...\n",
            "\tPreprocessing partition...\n",
            "\tComputing predictions...\n",
            "\t\tBatch 1/3\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\t\tBatch 2/3\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\t\tBatch 3/3\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "Partition 3/3:\n",
            "\tLoading partition...\n",
            "\tPreprocessing partition...\n",
            "\tComputing predictions...\n",
            "\t\tBatch 1/3\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\t\tBatch 2/3\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\t\tBatch 3/3\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Concatenating partitions predictions...\n",
            "Sorting predictions by filename...\n",
            "Serializing predictions...\n",
            "\tSerializing predictions for class 'aeroplane' to './results/VOC2012/Main/comp2_cls_test_aeroplane.txt'\n",
            "\tSerializing predictions for class 'bicycle' to './results/VOC2012/Main/comp2_cls_test_bicycle.txt'\n",
            "\tSerializing predictions for class 'bird' to './results/VOC2012/Main/comp2_cls_test_bird.txt'\n",
            "\tSerializing predictions for class 'boat' to './results/VOC2012/Main/comp2_cls_test_boat.txt'\n",
            "\tSerializing predictions for class 'bottle' to './results/VOC2012/Main/comp2_cls_test_bottle.txt'\n",
            "\tSerializing predictions for class 'bus' to './results/VOC2012/Main/comp2_cls_test_bus.txt'\n",
            "\tSerializing predictions for class 'car' to './results/VOC2012/Main/comp2_cls_test_car.txt'\n",
            "\tSerializing predictions for class 'cat' to './results/VOC2012/Main/comp2_cls_test_cat.txt'\n",
            "\tSerializing predictions for class 'chair' to './results/VOC2012/Main/comp2_cls_test_chair.txt'\n",
            "\tSerializing predictions for class 'cow' to './results/VOC2012/Main/comp2_cls_test_cow.txt'\n",
            "\tSerializing predictions for class 'diningtable' to './results/VOC2012/Main/comp2_cls_test_diningtable.txt'\n",
            "\tSerializing predictions for class 'dog' to './results/VOC2012/Main/comp2_cls_test_dog.txt'\n",
            "\tSerializing predictions for class 'horse' to './results/VOC2012/Main/comp2_cls_test_horse.txt'\n",
            "\tSerializing predictions for class 'motorbike' to './results/VOC2012/Main/comp2_cls_test_motorbike.txt'\n",
            "\tSerializing predictions for class 'person' to './results/VOC2012/Main/comp2_cls_test_person.txt'\n",
            "\tSerializing predictions for class 'pottedplant' to './results/VOC2012/Main/comp2_cls_test_pottedplant.txt'\n",
            "\tSerializing predictions for class 'sheep' to './results/VOC2012/Main/comp2_cls_test_sheep.txt'\n",
            "\tSerializing predictions for class 'sofa' to './results/VOC2012/Main/comp2_cls_test_sofa.txt'\n",
            "\tSerializing predictions for class 'train' to './results/VOC2012/Main/comp2_cls_test_train.txt'\n",
            "\tSerializing predictions for class 'tvmonitor' to './results/VOC2012/Main/comp2_cls_test_tvmonitor.txt'\n",
            "Mocking results for detection task...\n",
            "\tMocking detections for class 'aeroplane' to './results/VOC2012/Main/comp4_det_test_aeroplane.txt'\n",
            "\tMocking detections for class 'bicycle' to './results/VOC2012/Main/comp4_det_test_bicycle.txt'\n",
            "\tMocking detections for class 'bird' to './results/VOC2012/Main/comp4_det_test_bird.txt'\n",
            "\tMocking detections for class 'boat' to './results/VOC2012/Main/comp4_det_test_boat.txt'\n",
            "\tMocking detections for class 'bottle' to './results/VOC2012/Main/comp4_det_test_bottle.txt'\n",
            "\tMocking detections for class 'bus' to './results/VOC2012/Main/comp4_det_test_bus.txt'\n",
            "\tMocking detections for class 'car' to './results/VOC2012/Main/comp4_det_test_car.txt'\n",
            "\tMocking detections for class 'cat' to './results/VOC2012/Main/comp4_det_test_cat.txt'\n",
            "\tMocking detections for class 'chair' to './results/VOC2012/Main/comp4_det_test_chair.txt'\n",
            "\tMocking detections for class 'cow' to './results/VOC2012/Main/comp4_det_test_cow.txt'\n",
            "\tMocking detections for class 'diningtable' to './results/VOC2012/Main/comp4_det_test_diningtable.txt'\n",
            "\tMocking detections for class 'dog' to './results/VOC2012/Main/comp4_det_test_dog.txt'\n",
            "\tMocking detections for class 'horse' to './results/VOC2012/Main/comp4_det_test_horse.txt'\n",
            "\tMocking detections for class 'motorbike' to './results/VOC2012/Main/comp4_det_test_motorbike.txt'\n",
            "\tMocking detections for class 'person' to './results/VOC2012/Main/comp4_det_test_person.txt'\n",
            "\tMocking detections for class 'pottedplant' to './results/VOC2012/Main/comp4_det_test_pottedplant.txt'\n",
            "\tMocking detections for class 'sheep' to './results/VOC2012/Main/comp4_det_test_sheep.txt'\n",
            "\tMocking detections for class 'sofa' to './results/VOC2012/Main/comp4_det_test_sofa.txt'\n",
            "\tMocking detections for class 'train' to './results/VOC2012/Main/comp4_det_test_train.txt'\n",
            "\tMocking detections for class 'tvmonitor' to './results/VOC2012/Main/comp4_det_test_tvmonitor.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_filename = f'results.tgz'\n",
        "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
        "    tar.add(PRED_FOLDER, arcname=PRED_FOLDER)\n",
        "\n",
        "destination = BASE_DIR + f\"{model_filename}_{output_filename}\"\n",
        "shutil.move(output_filename, destination)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bAfowWfMR4jt",
        "outputId": "4ed79be6-e1f0-45fe-ad5a-49cf082d98e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/AML/project/test/model_base_resnet_results.tgz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdipEByykfns"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}